{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "155ef6b83b24db6d4e2e8991a36621b0bf03009eadef3ba8c0ac32a210378d6e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import geonamescache\n",
    "\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv(\"ufo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Date/Time                        City State      Shape        Duration  \\\n",
       "0  2/28/21 21:50          Monterrey (Mexico)   NaN   Changing       3 minutes   \n",
       "1  2/21/21 12:00  Littlehampton (UK/England)   NaN  Rectangle  several sconds   \n",
       "2  2/20/21 11:00                      Sydney   NaN      Cigar       2 minutes   \n",
       "3  2/19/21 19:34                       PATNA   NaN     Circle       2 seconds   \n",
       "4  2/18/21 18:00                         NaN   NaN     Circle           Photo   \n",
       "\n",
       "                                             Summary  Posted  \n",
       "0  I was putting my clothes to dry, when i notice...  3/2/21  \n",
       "1  Fast moving silver objects, visible through Bi...  3/2/21  \n",
       "2  2 craft seen looked initially like a satellite...  3/2/21  \n",
       "3  There was a circle object having 8 red lights ...  3/2/21  \n",
       "4  First photos sent back from perseverance on ma...  3/2/21  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date/Time</th>\n      <th>City</th>\n      <th>State</th>\n      <th>Shape</th>\n      <th>Duration</th>\n      <th>Summary</th>\n      <th>Posted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2/28/21 21:50</td>\n      <td>Monterrey (Mexico)</td>\n      <td>NaN</td>\n      <td>Changing</td>\n      <td>3 minutes</td>\n      <td>I was putting my clothes to dry, when i notice...</td>\n      <td>3/2/21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2/21/21 12:00</td>\n      <td>Littlehampton (UK/England)</td>\n      <td>NaN</td>\n      <td>Rectangle</td>\n      <td>several sconds</td>\n      <td>Fast moving silver objects, visible through Bi...</td>\n      <td>3/2/21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2/20/21 11:00</td>\n      <td>Sydney</td>\n      <td>NaN</td>\n      <td>Cigar</td>\n      <td>2 minutes</td>\n      <td>2 craft seen looked initially like a satellite...</td>\n      <td>3/2/21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2/19/21 19:34</td>\n      <td>PATNA</td>\n      <td>NaN</td>\n      <td>Circle</td>\n      <td>2 seconds</td>\n      <td>There was a circle object having 8 red lights ...</td>\n      <td>3/2/21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2/18/21 18:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Circle</td>\n      <td>Photo</td>\n      <td>First photos sent back from perseverance on ma...</td>\n      <td>3/2/21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# make sure we got it\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out NA city\n",
    "data = data[data[\"State\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  code        name fips  geonameid\n",
       "0   AK      Alaska   02    5879092\n",
       "1   AL     Alabama   01    4829764\n",
       "2   AR    Arkansas   05    4099753\n",
       "3   AZ     Arizona   04    5551752\n",
       "4   CA  California   06    5332921"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>name</th>\n      <th>fips</th>\n      <th>geonameid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AK</td>\n      <td>Alaska</td>\n      <td>02</td>\n      <td>5879092</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AL</td>\n      <td>Alabama</td>\n      <td>01</td>\n      <td>4829764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AR</td>\n      <td>Arkansas</td>\n      <td>05</td>\n      <td>4099753</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AZ</td>\n      <td>Arizona</td>\n      <td>04</td>\n      <td>5551752</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CA</td>\n      <td>California</td>\n      <td>06</td>\n      <td>5332921</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# prep state data for filtering\n",
    "states = pd.DataFrame(info for state, info in gc.get_us_states().items())\n",
    "states.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   geonameid          name  latitude  longitude countrycode  population  \\\n",
       "0    4046704     Fort Hunt  38.73289  -77.05803          US       16045   \n",
       "1    4048023      Bessemer  33.40178  -86.95444          US       26730   \n",
       "2    4048662       Paducah  37.08339  -88.60005          US       24864   \n",
       "3    4049979    Birmingham  33.52066  -86.80249          US      212461   \n",
       "4    4054378  Center Point  33.64566  -86.68360          US       16655   \n",
       "\n",
       "           timezone admin1code  \\\n",
       "0  America/New_York         VA   \n",
       "1   America/Chicago         AL   \n",
       "2   America/Chicago         KY   \n",
       "3   America/Chicago         AL   \n",
       "4   America/Chicago         AL   \n",
       "\n",
       "                                      alternatenames  \n",
       "0                                                 []  \n",
       "1  [Besemer, Bessemer, bei se mo, bes'semara, bes...  \n",
       "2  [PAH, Padaka, Padjuka, Paducah, Paduka, Pekin,...  \n",
       "3  [BHM, Bermincham, Bermingkham, Birmingam, Birm...  \n",
       "4  [Senter Pojnt, Sentr-Pojnt, sentara po'inta, s...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>geonameid</th>\n      <th>name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>countrycode</th>\n      <th>population</th>\n      <th>timezone</th>\n      <th>admin1code</th>\n      <th>alternatenames</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4046704</td>\n      <td>Fort Hunt</td>\n      <td>38.73289</td>\n      <td>-77.05803</td>\n      <td>US</td>\n      <td>16045</td>\n      <td>America/New_York</td>\n      <td>VA</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4048023</td>\n      <td>Bessemer</td>\n      <td>33.40178</td>\n      <td>-86.95444</td>\n      <td>US</td>\n      <td>26730</td>\n      <td>America/Chicago</td>\n      <td>AL</td>\n      <td>[Besemer, Bessemer, bei se mo, bes'semara, bes...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4048662</td>\n      <td>Paducah</td>\n      <td>37.08339</td>\n      <td>-88.60005</td>\n      <td>US</td>\n      <td>24864</td>\n      <td>America/Chicago</td>\n      <td>KY</td>\n      <td>[PAH, Padaka, Padjuka, Paducah, Paduka, Pekin,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4049979</td>\n      <td>Birmingham</td>\n      <td>33.52066</td>\n      <td>-86.80249</td>\n      <td>US</td>\n      <td>212461</td>\n      <td>America/Chicago</td>\n      <td>AL</td>\n      <td>[BHM, Bermincham, Bermingkham, Birmingam, Birm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4054378</td>\n      <td>Center Point</td>\n      <td>33.64566</td>\n      <td>-86.68360</td>\n      <td>US</td>\n      <td>16655</td>\n      <td>America/Chicago</td>\n      <td>AL</td>\n      <td>[Senter Pojnt, Sentr-Pojnt, sentara po'inta, s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# prep city data for filtering\n",
    "cities = pd.DataFrame(info for cityid, info in gc.get_cities().items() if info[\"countrycode\"] == \"US\")\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into US states and non (such as canadian provinces)\n",
    "us_data = data[data[\"State\"].isin(states[\"code\"])].reset_index()\n",
    "non_us_data = data[~data[\"State\"].isin(states[\"code\"])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of strangeish entries (non-alpha):\n4926\nnumber of entries in format <city> (<something>)\n2203\n"
     ]
    }
   ],
   "source": [
    "# check what city entries have non-word characters to find patterns\n",
    "weird_cities = us_data[us_data[\"City\"].str.contains(\"[^a-zA-Z ]\", na=False)]\n",
    "cities_notes = us_data[us_data[\"City\"].str.contains(\"[a-zA-Z- ] \\(\", na=False)]\n",
    "print(\"number of strangeish entries (non-alpha):\")\n",
    "print(weird_cities.shape[0])\n",
    "print(\"number of entries in format <city> (<something>)\")\n",
    "print(cities_notes.shape[0])"
   ]
  },
  {
   "source": [
    "4,926 is quite a few. Over half of these are just using parenthases for notes, so we can clean those."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_notes(x):\n",
    "    x = str(x)\n",
    "    regexpr = re.compile(\"[a-zA-Z- ] \\(\")\n",
    "    if regexpr.search(x):\n",
    "        return x[0:x.find(\" (\")]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "us_data[\"City\"] = us_data[\"City\"].apply(rm_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# test if we've reduced that a little\n",
    "cities_notes = us_data[us_data[\"City\"].str.contains(\"[a-zA-Z- ] \\(\", na=False)]\n",
    "print(cities_notes.shape[0])"
   ]
  },
  {
   "source": [
    "There are a few where the exact coords are given. We can save these for later."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_direct_coords = us_data[us_data[\"City\"].str.contains(\"[0-9]+\\.[0-9]+\\s+[0-9]+\\.[0-9]+\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data[\"city_lower\"] = us_data[\"City\"].str.lower()\n",
    "cities[\"city_lower\"] = cities[\"name\"].str.lower()\n",
    "cities[\"State\"] = cities[\"admin1code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_matched_cities = pd.merge(us_data, cities[[\"latitude\", \"longitude\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"inner\")\n",
    "# us_data[us_data[\"City\"].str.lower().isin(cities[\"name\"].str.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "got 49956 out of initial 87784\n"
     ]
    }
   ],
   "source": [
    "print(\"got {} out of initial {}\".format(us_data_matched_cities.shape[0], us_data.shape[0]))"
   ]
  },
  {
   "source": [
    "Let's take a look at what didn't match"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_unmatched = us_data[~us_data[\"City\"].str.lower().isin(cities[\"name\"].str.lower())]"
   ]
  },
  {
   "source": [
    "A lot of these are cities not recognized by the city list. Let's use a more comprehensive city list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['city',\n",
       " 'city_ascii',\n",
       " 'state_id',\n",
       " 'state_name',\n",
       " 'county_fips',\n",
       " 'county_name',\n",
       " 'lat',\n",
       " 'lng',\n",
       " 'population',\n",
       " 'density',\n",
       " 'source',\n",
       " 'military',\n",
       " 'incorporated',\n",
       " 'timezone',\n",
       " 'ranking',\n",
       " 'zips',\n",
       " 'id']"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "newcities = pd.read_csv(\"uscities.csv\")\n",
    "newcities.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "got 71753 out of initial 87784\n"
     ]
    }
   ],
   "source": [
    "newcities[\"city_lower\"] = newcities[\"city_ascii\"].str.lower()\n",
    "newcities[\"State\"] = newcities[\"state_id\"]\n",
    "\n",
    "us_data_matched_cities = pd.merge(us_data, newcities[[\"lat\", \"lng\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"inner\")\n",
    "#us_data[us_data[\"City\"].str.lower().isin(newcities[\"city_ascii\"].str.lower())]\n",
    "print(\"got {} out of initial {}\".format(us_data_matched_cities.shape[0], us_data.shape[0]))"
   ]
  },
  {
   "source": [
    "Let's see again what didn't match."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_unmatched = us_data[~us_data[\"City\"].str.lower().isin(newcities[\"city_ascii\"].str.lower())]"
   ]
  },
  {
   "source": [
    "A lot of these are places rather than cities, with a lot probably being unincorporated townships, etc. Quite a few would appear to be along the lines of 'New York City', which doesn't match because it's not 'New York'. Let's get whatever we can by removing 'city' from these."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_city(x):\n",
    "    x = str(x)\n",
    "    if \"city\" in x.lower():\n",
    "        return x[0:x.lower().find(\" city\")]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-70-f78948efa2a9>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  us_data_unmatched[\"City\"] = us_data_unmatched[\"City\"].apply(rm_city)\n"
     ]
    }
   ],
   "source": [
    "us_data_unmatched[\"City\"] = us_data_unmatched[\"City\"].apply(rm_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_additional_matched_cities = pd.merge(us_data_unmatched, newcities[[\"lat\", \"lng\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"inner\")\n",
    "#us_data_unmatched[us_data_unmatched[\"City\"].str.lower().isin(newcities[\"city_ascii\"].str.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Date/Time, City, State, Shape, Duration, Summary, Posted, city_lower, lat, lng]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Date/Time</th>\n      <th>City</th>\n      <th>State</th>\n      <th>Shape</th>\n      <th>Duration</th>\n      <th>Summary</th>\n      <th>Posted</th>\n      <th>city_lower</th>\n      <th>lat</th>\n      <th>lng</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "us_additional_matched_cities.head()"
   ]
  },
  {
   "source": [
    "Huh, nothing. Oh well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns and reset the index\n",
    "us_data_matched_cities.drop(columns=[\"Summary\", \"index\"], inplace=True)\n",
    "us_data_matched_cities.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "source": [
    "This would appear to be the best it gets without significantly more in-depth work, so I'll call it here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_matched_cities.to_csv(\"ufo_data_us_cleaned_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final unmatched ones\n",
    "us_data_unmatched = pd.merge(us_data, newcities[[\"lat\", \"lng\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"outer\", indicator=\"source\")\n",
    "us_data_unmatched = us_data_unmatched[us_data_unmatched.source.eq('left_only')].drop('source', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}