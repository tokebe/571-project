{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import geonamescache\n",
    "\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv(\"../Data/ufo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/28/21 21:50</td>\n",
       "      <td>Monterrey (Mexico)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changing</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>I was putting my clothes to dry, when i notice...</td>\n",
       "      <td>3/2/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/21/21 12:00</td>\n",
       "      <td>Littlehampton (UK/England)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rectangle</td>\n",
       "      <td>several sconds</td>\n",
       "      <td>Fast moving silver objects, visible through Bi...</td>\n",
       "      <td>3/2/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/20/21 11:00</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cigar</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>2 craft seen looked initially like a satellite...</td>\n",
       "      <td>3/2/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/19/21 19:34</td>\n",
       "      <td>PATNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circle</td>\n",
       "      <td>2 seconds</td>\n",
       "      <td>There was a circle object having 8 red lights ...</td>\n",
       "      <td>3/2/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/21 18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Photo</td>\n",
       "      <td>First photos sent back from perseverance on ma...</td>\n",
       "      <td>3/2/21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date/Time                        City State      Shape        Duration  \\\n",
       "0  2/28/21 21:50          Monterrey (Mexico)   NaN   Changing       3 minutes   \n",
       "1  2/21/21 12:00  Littlehampton (UK/England)   NaN  Rectangle  several sconds   \n",
       "2  2/20/21 11:00                      Sydney   NaN      Cigar       2 minutes   \n",
       "3  2/19/21 19:34                       PATNA   NaN     Circle       2 seconds   \n",
       "4  2/18/21 18:00                         NaN   NaN     Circle           Photo   \n",
       "\n",
       "                                             Summary  Posted  \n",
       "0  I was putting my clothes to dry, when i notice...  3/2/21  \n",
       "1  Fast moving silver objects, visible through Bi...  3/2/21  \n",
       "2  2 craft seen looked initially like a satellite...  3/2/21  \n",
       "3  There was a circle object having 8 red lights ...  3/2/21  \n",
       "4  First photos sent back from perseverance on ma...  3/2/21  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we got it\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out NA city\n",
    "data = data[data[\"State\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>fips</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>02</td>\n",
       "      <td>5879092</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>4829764</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>05</td>\n",
       "      <td>4099753</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>04</td>\n",
       "      <td>5551752</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>06</td>\n",
       "      <td>5332921</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code fips  geonameid        name\n",
       "0   AK   02    5879092      Alaska\n",
       "1   AL   01    4829764     Alabama\n",
       "2   AR   05    4099753    Arkansas\n",
       "3   AZ   04    5551752     Arizona\n",
       "4   CA   06    5332921  California"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep state data for filtering\n",
    "states = pd.DataFrame(info for state, info in gc.get_us_states().items())\n",
    "states.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin1code</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>population</th>\n",
       "      <th>timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VA</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>4046704</td>\n",
       "      <td>38.73289</td>\n",
       "      <td>-77.05803</td>\n",
       "      <td>Fort Hunt</td>\n",
       "      <td>16045</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>[Besemer, Bessemer, bei se mo, bes'semara, bes...</td>\n",
       "      <td>US</td>\n",
       "      <td>4048023</td>\n",
       "      <td>33.40178</td>\n",
       "      <td>-86.95444</td>\n",
       "      <td>Bessemer</td>\n",
       "      <td>26730</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KY</td>\n",
       "      <td>[PAH, Padaka, Padjuka, Paducah, Paduka, Pekin,...</td>\n",
       "      <td>US</td>\n",
       "      <td>4048662</td>\n",
       "      <td>37.08339</td>\n",
       "      <td>-88.60005</td>\n",
       "      <td>Paducah</td>\n",
       "      <td>24864</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>[BHM, Bermincham, Bermingkham, Birmingam, Birm...</td>\n",
       "      <td>US</td>\n",
       "      <td>4049979</td>\n",
       "      <td>33.52066</td>\n",
       "      <td>-86.80249</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>212461</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>[Senter Pojnt, Sentr-Pojnt, sentara po'inta, s...</td>\n",
       "      <td>US</td>\n",
       "      <td>4054378</td>\n",
       "      <td>33.64566</td>\n",
       "      <td>-86.68360</td>\n",
       "      <td>Center Point</td>\n",
       "      <td>16655</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  admin1code                                     alternatenames countrycode  \\\n",
       "0         VA                                                 []          US   \n",
       "1         AL  [Besemer, Bessemer, bei se mo, bes'semara, bes...          US   \n",
       "2         KY  [PAH, Padaka, Padjuka, Paducah, Paduka, Pekin,...          US   \n",
       "3         AL  [BHM, Bermincham, Bermingkham, Birmingam, Birm...          US   \n",
       "4         AL  [Senter Pojnt, Sentr-Pojnt, sentara po'inta, s...          US   \n",
       "\n",
       "   geonameid  latitude  longitude          name  population          timezone  \n",
       "0    4046704  38.73289  -77.05803     Fort Hunt       16045  America/New_York  \n",
       "1    4048023  33.40178  -86.95444      Bessemer       26730   America/Chicago  \n",
       "2    4048662  37.08339  -88.60005       Paducah       24864   America/Chicago  \n",
       "3    4049979  33.52066  -86.80249    Birmingham      212461   America/Chicago  \n",
       "4    4054378  33.64566  -86.68360  Center Point       16655   America/Chicago  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep city data for filtering\n",
    "cities = pd.DataFrame(info for cityid, info in gc.get_cities().items() if info[\"countrycode\"] == \"US\")\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into US states and non (such as canadian provinces)\n",
    "us_data = data[data[\"State\"].isin(states[\"code\"])].reset_index()\n",
    "non_us_data = data[~data[\"State\"].isin(states[\"code\"])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of strangeish entries (non-alpha):\n",
      "4926\n",
      "number of entries in format <city> (<something>)\n",
      "2203\n"
     ]
    }
   ],
   "source": [
    "# check what city entries have non-word characters to find patterns\n",
    "weird_cities = us_data[us_data[\"City\"].str.contains(\"[^a-zA-Z ]\", na=False)]\n",
    "cities_notes = us_data[us_data[\"City\"].str.contains(\"[a-zA-Z- ] \\(\", na=False)]\n",
    "print(\"number of strangeish entries (non-alpha):\")\n",
    "print(weird_cities.shape[0])\n",
    "print(\"number of entries in format <city> (<something>)\")\n",
    "print(cities_notes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4,926 is quite a few. Over half of these are just using parenthases for notes, so we can clean those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_notes(x):\n",
    "    x = str(x)\n",
    "    regexpr = re.compile(\"[a-zA-Z- ] \\(\")\n",
    "    if regexpr.search(x):\n",
    "        return x[0:x.find(\" (\")]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "us_data[\"City\"] = us_data[\"City\"].apply(rm_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# test if we've reduced that a little\n",
    "cities_notes = us_data[us_data[\"City\"].str.contains(\"[a-zA-Z- ] \\(\", na=False)]\n",
    "print(cities_notes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few where the exact coords are given. We can save these for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_direct_coords = us_data[us_data[\"City\"].str.contains(\"[0-9]+\\.[0-9]+\\s+[0-9]+\\.[0-9]+\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data[\"city_lower\"] = us_data[\"City\"].str.lower()\n",
    "cities[\"city_lower\"] = cities[\"name\"].str.lower()\n",
    "cities[\"State\"] = cities[\"admin1code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_matched_cities = pd.merge(us_data, cities[[\"latitude\", \"longitude\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"inner\")\n",
    "# us_data[us_data[\"City\"].str.lower().isin(cities[\"name\"].str.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 49956 out of initial 87784\n"
     ]
    }
   ],
   "source": [
    "print(\"got {} out of initial {}\".format(us_data_matched_cities.shape[0], us_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what didn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_unmatched = us_data[~us_data[\"City\"].str.lower().isin(cities[\"name\"].str.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these are cities not recognized by the city list. Let's use a more comprehensive city list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'city_ascii',\n",
       " 'state_id',\n",
       " 'state_name',\n",
       " 'county_fips',\n",
       " 'county_name',\n",
       " 'lat',\n",
       " 'lng',\n",
       " 'population',\n",
       " 'density',\n",
       " 'source',\n",
       " 'military',\n",
       " 'incorporated',\n",
       " 'timezone',\n",
       " 'ranking',\n",
       " 'zips',\n",
       " 'id']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcities = pd.read_csv(\"../Data/uscities.csv\")\n",
    "newcities.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 71805 out of initial 87784\n"
     ]
    }
   ],
   "source": [
    "newcities[\"city_lower\"] = newcities[\"city_ascii\"].str.lower()\n",
    "newcities[\"State\"] = newcities[\"state_id\"]\n",
    "\n",
    "us_data_matched_cities = pd.merge(us_data, newcities[[\"lat\", \"lng\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"inner\")\n",
    "#us_data[us_data[\"City\"].str.lower().isin(newcities[\"city_ascii\"].str.lower())]\n",
    "print(\"got {} out of initial {}\".format(us_data_matched_cities.shape[0], us_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see again what didn't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_unmatched = us_data[~us_data[\"City\"].str.lower().isin(newcities[\"city_ascii\"].str.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these are places rather than cities, with a lot probably being unincorporated townships, etc. Quite a few would appear to be along the lines of 'New York City', which doesn't match because it's not 'New York'. Let's get whatever we can by removing 'city' from these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_city(x):\n",
    "    x = str(x)\n",
    "    if \"city\" in x.lower():\n",
    "        return x[0:x.lower().find(\" city\")]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hans/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "us_data_unmatched[\"City\"] = us_data_unmatched[\"City\"].apply(rm_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_additional_matched_cities = pd.merge(us_data_unmatched, newcities[[\"lat\", \"lng\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"inner\")\n",
    "#us_data_unmatched[us_data_unmatched[\"City\"].str.lower().isin(newcities[\"city_ascii\"].str.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Posted</th>\n",
       "      <th>city_lower</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Date/Time, City, State, Shape, Duration, Summary, Posted, city_lower, lat, lng]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_additional_matched_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, nothing. Oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns and reset the index\n",
    "us_data_matched_cities.drop(columns=[\"Summary\", \"index\"], inplace=True)\n",
    "us_data_matched_cities.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would appear to be the best it gets without significantly more in-depth work, so I'll call it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_matched_cities.to_csv(\"../Data/ufo_data_us_cleaned_v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final unmatched ones\n",
    "us_data_unmatched = pd.merge(us_data, newcities[[\"lat\", \"lng\", \"city_lower\", \"State\"]], on=[\"city_lower\", \"State\"], how=\"outer\", indicator=\"source\")\n",
    "us_data_unmatched = us_data_unmatched[us_data_unmatched.source.eq('left_only')].drop('source', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
